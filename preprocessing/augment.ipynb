{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from collections import defaultdict\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "classes = ['A', 'B1', 'B2', 'B4', 'B5', 'B6', 'G']\n",
    "target_count_per_class = 75\n",
    "\n",
    "path = r\"C:\\Users\\Olenka\\PycharmProjects\\violence_detection\\train\"\n",
    "class_counts = defaultdict(int)\n",
    "video_paths_by_class = defaultdict(list)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def extract_labels(file):\n",
    "    parts = file[:-4].split(\"label_\")\n",
    "    if len(parts) < 2:\n",
    "        return [0] * len(classes)\n",
    "    return [1 if cls in parts[1].split('-') else 0 for cls in classes]\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for file in os.listdir(path):\n",
    "    if file.endswith('.mp4'):\n",
    "        labels = extract_labels(file) \n",
    "        if sum(labels) == 1:\n",
    "            label_index = labels.index(1)\n",
    "            cls = classes[label_index]\n",
    "            class_counts[cls] += 1\n",
    "            video_paths_by_class[cls].append(os.path.join(path, file))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "class_counts",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def add_noise(frame, level=5):\n",
    "    noise = np.random.normal(0, level, frame.shape).astype(np.int16)\n",
    "    frame_int = frame.astype(np.int16)\n",
    "    noisy = frame_int + noise\n",
    "    noisy = np.clip(noisy, 0, 255).astype(np.uint8)\n",
    "    return noisy"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def adjust_brightness(frame, level=0.2):\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    hsv = np.array(hsv, dtype=np.float64)\n",
    "    hsv[:, :, 2] = hsv[:, :, 2] * (1 + level)\n",
    "    hsv[:, :, 2][hsv[:, :, 2] > 255] = 255\n",
    "    hsv = np.array(hsv, dtype=np.uint8)\n",
    "    return cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def apply_blur(frame, sigma=0.5):\n",
    "    ksize = int(2 * round(3 * sigma) + 1)\n",
    "    return cv2.GaussianBlur(frame, (ksize, ksize), sigma)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def adjust_contrast(frame, level=30):\n",
    "    alpha = 1.0 + (level / 100.0) \n",
    "    beta = 0\n",
    "    try:\n",
    "        return cv2.convertScaleAbs(frame, alpha=alpha, beta=beta)\n",
    "    except Exception as e:\n",
    "        print(f\"Error adjusting contrast: {e}\")\n",
    "        return frame"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def horizontal_flip(frame):\n",
    "    return cv2.flip(frame, 1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "augmentations = [\n",
    "    lambda frame: add_noise(frame, level=random.choice([15, 25, 35])),\n",
    "    lambda frame: adjust_brightness(frame, level=random.choice([-0.4, -0.2, 0.2, 0.4])),\n",
    "    lambda frame: apply_blur(frame, sigma=random.choice([0.1, 0.3, 0.5])),\n",
    "    lambda frame: adjust_contrast(frame, level=random.randint(-50, 50)),\n",
    "    horizontal_flip\n",
    "]\n",
    "\n",
    "def get_augmentation_techniques():\n",
    "  number = random.randint(2, 4)\n",
    "  number_of_techniques = random.sample([i for i in range(5)], k=number)\n",
    "  return number_of_techniques"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "YAQhRnflHu6X"
   },
   "cell_type": "code",
   "source": [
    "def augment(target_class):\n",
    "    output_dir = path\n",
    "\n",
    "    augmented_videos = defaultdict(list)\n",
    "    \n",
    "    for cls in classes:\n",
    "        if cls != target_class:\n",
    "            continue\n",
    "    \n",
    "        current_count = class_counts[cls]\n",
    "        if current_count >= target_count_per_class:\n",
    "            continue\n",
    "    \n",
    "        videos = video_paths_by_class[cls]\n",
    "        i = 0\n",
    "        while current_count + len(augmented_videos[cls]) < target_count_per_class:\n",
    "            original_path = videos[i % len(videos)]\n",
    "    \n",
    "            cap = cv2.VideoCapture(original_path)\n",
    "            fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "            frames = []\n",
    "            while True:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                frames.append(frame)\n",
    "            cap.release()\n",
    "    \n",
    "            aug_indices = get_augmentation_techniques()\n",
    "            selected_augs = [augmentations[idx] for idx in aug_indices]\n",
    "    \n",
    "            aug_frames = []\n",
    "            for frame in frames:\n",
    "                for aug in selected_augs:\n",
    "                    frame = aug(frame)\n",
    "                aug_frames.append(frame)\n",
    "    \n",
    "            filename = f\"{i}-aug_label_{cls}-0-0.mp4\"\n",
    "            output_path = os.path.join(output_dir, filename)\n",
    "    \n",
    "            out = cv2.VideoWriter(\n",
    "                output_path,\n",
    "                cv2.VideoWriter_fourcc(*'mp4v'),\n",
    "                fps,\n",
    "                (width, height)\n",
    "            )\n",
    "    \n",
    "            for frame in aug_frames:\n",
    "                frame_bgr = cv2.cvtColor(np.array(frame), cv2.COLOR_RGB2BGR)\n",
    "                out.write(frame_bgr)\n",
    "            out.release()\n",
    "    \n",
    "            augmented_videos[cls].append(output_path)\n",
    "            i += 1\n",
    "            print(f\"Saved: {filename}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "augment(\"B4\")\n",
    "augment(\"B5\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ]
}
